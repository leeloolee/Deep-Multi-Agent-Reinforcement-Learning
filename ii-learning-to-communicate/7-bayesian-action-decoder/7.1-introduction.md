# 7.1 Introduction

DMARL method의 SOTA로는 이전에 했던 DIAL같은 communication protocol을 배우는 종류의 접근입니다. 하지만 이러한 접근에는 두가지 제한점이 있었습니다. 

* 첫째로, 이는 오직 cheap-talk channel에만 적용된다는 점입니다. 이는 communication은 환경에 아무런 영향을 끼치지 못하는 action입니다.
* 둘째로, 이는 communication과 다른 agent들의 행동이 왜 했는지에 대한 결합이 존재하지 않습니다. 

이런 분야에서 잘 알려진 도전과제로는 [Hanabi](https://www.youtube.com/watch?v=IWe07PDo2yE)\(룰에 대해 영상을 보시는 것을 추천합니다.\)가 있습니다. 이는 자신의 패를 보지 못하는 상태에서 서로 협력해 최대의 점수를 만드는 게임으로, agent끼리 소통하는 효과적인 convention을 가져야만 합니다. 여기서는 cheap-talk channel이 없기 때문에, 이전과는 다른 방법을 사용해야만 합니다. Hanabi에서의 행동은 상대 패의 정보를 내포하거나, 등록, 혹은 버리는 행위가 있는데, 이러한 행동에서의 의미는 두가지의 레벨로 나눠볼 수 있습니다. 첫번째 레벨로는 그 행위 자체로 주는 정보입니다. 예를 들면 상대방이 들고있는 카드가 어떤 카드인지 알려주는 것은 그 자체로 reward를 높이기 위한 좋은 정보가 될 수 있습니다. 둘째로는 그 정보로부터 내포하고있는 정보입니다. 예로 들자면, 어떤 agent가 한 행동을 하거나 하지않는다면, 그에따른 이유가 있을 것임을에 대한 정보입니다. 이러한 정보를 얻기위해선 어떠한 convention이 있어야 하고, 좋은 전략을 만들어내는데 필수적입니다.

 이러한 문제를 해결하기 위해 여기서는 Bayesian action decoder\(BAD\)를 제안합니다. 이는 Nayyar의 연구에서 영감을 받았는데, BAD에서 사용하는 public belief Markov Decision Process  정의하기 때문입니다. 이는 action space가 DNN을 통해 parameterized되고, public state로 부터 sampling되는 deterministic partial policies의 집합입니다. 다시말해서 이는 개인의 observation을 environment action으로 mapping하는 deterministic partial policy의 space안에서 행동해 agent가 public belief state에서만 optimal policy를 찾는다는 뜻 입니다.

만약 한 agent가 다른 agent의 action을 관찰하면 public belief가 가능한 state 집합\(다른 agent가 고른 관측된 행동 집합\)에서 sampling되어 갱신됩니다. 이는 **Theory of mind** 종류와 비슷한데, 이는 왜 이러한 행동을 하는지, 개인의 관측으로부터 어떤 정보를 얻어낼 수 있을지에 대해 이해라려 합니다.

 여기서는 BAD의 유효성에 대해 설명을 하고, Hanabi의 변형 버전에 적용함으로써, 이전의 시도들보다 훨씬 좋은 성능을 보여줍니다.


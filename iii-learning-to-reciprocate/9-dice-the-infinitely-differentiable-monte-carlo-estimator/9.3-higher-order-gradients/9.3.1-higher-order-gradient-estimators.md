# 9.3.1 Higher Order Gradient Estimators

 score function estimator의 미분을 다시 한번 $$\nabla_\theta \mathcal{L}$$로 표현해 나타내 보겠습니다.\(사실 9.2의 background에서 미리 진행했기 때문에 쉽게 넘어갈 수 있습니다.\)

                                                                 $$ \nabla_\theta \mathcal{L} = \nabla_{\theta}\mathbb{E}_x[f(x;\theta)]$$

                                                                           $$= \nabla_{\theta}\sum_xp(x;\theta)f(x;\theta)$$

                                                                           $$= \sum_x\nabla_{\theta}(p(x;\theta)f(x;\theta))$$

                                                                           $$= \sum_x(\nabla_{\theta}p(x;\theta)f(x;\theta)+p(x;\theta)\nabla_{\theta}f(x;\theta))$$

                                                                           $$= \sum_x(p(x;\theta)f(x;\theta)\nabla_{\theta}\log{p(x;\theta)}+p(x;\theta)\nabla_{\theta}f(x;\theta))$$

                                                                           $$= \mathbb{E}[f(x;\theta)\nabla_{\theta}\log{p(x;\theta)}+\nabla_{\theta}f(x;\theta))]$$

                                                                           $$= \mathbb{E}[g(x;\theta)]$$

 $$g(x;\theta)$$는 $$\mathbb{E}_x[f(x;\theta)]$$의 gradient로 두가지 term으로 나타낼 수있습니다.

*  $$f(x;\theta)\nabla_\theta\log(p(x;\theta))$$는 SF trick에 의해 만들어집니다.
* $$ \nabla_\theta f(x;\theta)$$는 가끔 $$f$$가 $$\theta$$가 아닌$$x$$로 이루어졌기 때문에 종종 제외되는 경향을 보였습니다. 하지만, $$g$$ 는 $$x$$와 $$\theta$$ 모두로 이루어졌기 때문에, 제외되지 않습니다. 

  여기서는 높은 차수의 $$\mathcal{L}$$을 추정하기 위해 SL의 접근 방식으로 $$\nabla_\theta\mathbb{E}_x [g(x;\theta)]$$에 적용하는데, 다음 장에서 이 같은 접근이 실패함을 보입니다.


# 2.2 Multi-Agent Settings

이제 MARL에서의 formalization을 알아보겠습니다.

* $$ G = <S,U,P,r,Z,O,n,\gamma>$$
  * $$ S $$: agent가 위치한 state에 대한 전체 집합입니다.
  * $$U$$: 각 agent가 취할 수 있는 action에 대한 전체 집합입니다.
    * 한 agent의 action $$u^a \in U$$에 대해, n개의 agent에 대한 joint action은 $$ \bold{u} \in \bold{U} \equiv{U}^n $$로 나타낼 수 있습니다.
  * $$P$$: $$P(s\ |s,\bm{u}) \rightarrow$$ 한 state에서 joint action $$\bold{u}$$에 의해 다음 state가 될 확률에 대한 집합입니다.
  * $$r$$: $$r(s,\bold{u},a) : S\times \bold{U} \times A \rightarrow$$  한 state 에서 joint action $$\bold{U}$$에 의해 한 agent가 받는 reward scalar입니다.
  * $$Z$$: observation 전체에 대한 집합입니다. 어느 시점 $$t$$에서의 한 agent에 대한 observation $$ o^a_t $$가 있을 때, 이는 모두 $$o^a_t \in Z $$로 나타낼 수 있습니다.
  * $$O$$: observation function입니다.  agent가 어느 state에 존재할 때, observable한 영역은 다음과 같이 나타낼 수 있습니다. $$O(s,a) : S \times A \rightarrow Z $$
  * $$n$$: Agent의 개수입니다. 이때 Agent $$a $$는 전체 actor에 대한 집합$$A$$에 속하게 됩니다. $$a \in A \equiv \{1,...,n\} $$
  * $$\gamma $$: discount factor 입니다.




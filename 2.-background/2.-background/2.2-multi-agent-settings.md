# 2.2 Multi-Agent Settings

이제 MARL에서의 formalization을 알아보겠습니다.

* $$ G = <S,U,P,r,Z,O,n,\gamma>$$
  * $$ S $$: n개의 Agent들이 놓여있는 전 state space에 대한 집합입니다.
  * $$U$$: 전체 action space에 대한 집합입니다.
  * $$P$$: n개의 Agent들에 의한 joint action $$\bold{u}$$에 대한 한 state 집합에서 다음 state가 될 확률에 대한 집합입니다.
    * 한 agent의 action $$u^a \in U$$에 대해, n개의 agent에 대한 joint action은 $$ \bold{u} \in \bold{U} \equiv{U}^n $$로 나타낼 수 있습니다.
  * $$r$$: 전체 agent에 대한 state $$S$$에서 joint action $$\bold{U}$$사이의 한 agent의 action $$a$$로 인해 받는 reward 에 대한 scalar입니다.
    * $$r(s,\bold{u},a) : S\times \bold{U} \times A \rightarrow \mathbb{R} $$로 나타낼 수 있습니다.
  * $$Z$$: observation 전체에 대한 집합입니다. 어느 시점 $$t$$에서의 한 agent에 대한 observation $$ o^a_t $$가 있을 때, 이는 모두 $$o^a_t \in Z $$로 나타낼 수 있습니다.
  * $$O$$: observation function입니다.  agent들이 어느 state집합에 존재할 때, observate가능한 영역은 다음과 같이 나타낼 수 있습니다. $$O(s,a) : S \times A \rightarrow Z $$
  * $$n$$: Agent의 개수입니다. 이때 Agent $$a $$는 전체 actor에 대한 집합$$A$$에 속하게 됩니다. $$a \in A \equiv \{1,...,n\} $$
  * $$\gamma $$: discount factor 입니다.




# 2.6 Centralised Training, Decentralised Execution

처음에는 Decentralised Execution이라는 단어 자체가 centralised critic을 가지고, 그 critic만 agent에게 global reward를 내려주고, agent는 local observation을 계속 유지하는줄 알았는데 잘못 이해하고 있었습니다.

agent가 centralised training중에는 local observation뿐만이 아닌 추가적인 정보를 받으며, 학습을 진행합니다. 그런 뒤 마지막에만 agent의 policy가 이런 추가적인 정보에 의존하지 않으면 됩니다. 이는 그렇지 않은 것보다 굉장히 효율적인 학습을 보이는데, 이미 Dec-POMDP상황에선 표준으로 사용되는 방법들입니다. 심지어 general-sum상황에서도 이런 학습방법이 유효한데, 결국 마지막 policy만 다른 agent의 전략등에 대한 정보를 얻지 않아도 되는 상태만 만들면 되는 것입니다.


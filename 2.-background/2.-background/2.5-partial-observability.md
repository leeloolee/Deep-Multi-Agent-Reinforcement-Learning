# 2.5 Partial Observability

 agent가 state를 부분관측할 수 있을 때, 그 observation에 대한 function을 앞에서 정의했듯이 다음과 같이 나타낼 수 있습니다.

                                                                      $$ O(s,a):S\times A \rightarrow Z $$

 이에 따른\(partially observable 상황에서의\) agent의 policy를 정의하도록 하겠습니다. 

 policy의 action은 partially observable했던 history\(trajectory\)에 의해 결정되기 때문에 다음과 같이 표현할 수 있습니다.

                                                                 $$ \pi^a(u^a|\tau^a):T\times U \rightarrow [0,1] $$

                                                                      $$ \tau^a \in T \equiv (Z \times U)^*$$ 

\(star 기호는 dynamic length에 대해 표현했다고 판단했습니다.\)

 이 때, history에 대한 통계량을 충분히 mapping해야하는데 이전의 연구들에서 Recurrent neural network 계열이 좋은 성능을 보임을 보았습니다.

 또한 여기서는 reward를 agent가 직접관측하는게 아니라면 observation function에 들어가지 않는다고 판단했습니다.


# 5.4.1 Architecture

여기서는 recurrent DQN architecture를 사용했는데, agent끼리의 communication은 따로 고려하지 않았습니다. 여기서는 두가지 다른 모델을 사용하는데, 하나는 fully connected layer를 사용하고 다른 하나는 GRU를 사용합니다. rate of exploration을 1부터 0.02까지 1500episode동안 선형적으로 줄였고, 총 2500 episode를 진행했습니다. batch size는 30/n 으로 하였으며, variance를 줄이기 위해 importance weights를 0.01에서 2로 clipping했고, 1/\(n-1\)로 나눠 normalization하였습니다. 또한 learning rate를 일정하게 유지하기 위해, importance weights에 그 running rate을 나눠줬습니다.


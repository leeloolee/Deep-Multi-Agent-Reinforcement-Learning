# 5.5.1 Importance Sampling

XP+IS는 XP보다 나은 성능을 보여주는데, XP+IS도 앞에서 유도한 수식에서 보면 partially observation한 문제 때문에, approximation을 이용했기 때문에 문제점이 생깁니다. 학습 초기에, importance weights이 작아 variance가 낮을 땐, 굉장히 잘 학습이 되지만, 학습이 되며 점점 variance가 커지면, 문제가 생깁니다. 

~~importance weights의 다수는~~ $$\epsilon(1-\epsilon)\approx \epsilon$$~~보다 작거나 같은데, 이는 몇몇의 experiences만 학습에 사용되게되게 됩니다.~~ $$ \epsilon$$~~은 크게 유지되어야하고, importance weights의 variance는 낮게 유지되어야 합니다.~~


# 4.8 Conclusion & Future Work

4장에서는 MACKRL에 대해 설명했습니다. 이 method는 common knowledge를 이용해 agent가 decentralized된 상태에서도 action의 joint action space를 학습할 수 있도록 하였습니다. MACKRL은 matrix game에서 확실히 좋은 성능을 보였는데, future work로, MACKRL을 많은 agent에 적용하고, common knowledge를 각자 분리돼서 가지고 있는게 아닌 trajectories로부터 추론할 수 있도록 할 것입니다. 다음 chapter에서는 MARL의 non-stationary한 환경에서의 Q-learning에 대해 보겠습니다.

